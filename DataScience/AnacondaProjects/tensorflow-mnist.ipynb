{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist_data = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "no_classes = 10\n",
    "batch_size = 100\n",
    "total_batches = 200\n",
    "x_input = tf.placeholder(tf.float32, shape=[None, input_size])\n",
    "y_input = tf.placeholder(tf.float32, shape=[None, no_classes])\n",
    "weights = tf.Variable(tf.random_normal([input_size, no_classes]))\n",
    "bias = tf.Variable(tf.random_normal([no_classes]))\n",
    "logits = tf.matmul(x_input, weights) + bias\n",
    "softmax_cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y_input, logits=logits)\n",
    "loss_operation = tf.reduce_mean(softmax_cross_entropy)\n",
    "optimiser = tf.train.GradientDescentOptimizer(learning_rate=0.5).minimize(loss_operation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.9087\n",
      "11.9835\n",
      "11.1306\n",
      "8.24526\n",
      "9.0964\n",
      "9.33317\n",
      "8.88388\n",
      "6.42924\n",
      "6.92246\n",
      "6.92365\n",
      "5.72368\n",
      "6.05115\n",
      "5.12042\n",
      "5.61749\n",
      "4.69223\n",
      "4.8959\n",
      "4.14388\n",
      "3.61241\n",
      "3.48442\n",
      "3.4457\n",
      "3.91726\n",
      "4.31503\n",
      "4.54763\n",
      "3.88725\n",
      "4.39838\n",
      "2.97927\n",
      "2.72216\n",
      "2.98743\n",
      "3.8872\n",
      "2.86267\n",
      "3.05178\n",
      "3.28802\n",
      "2.75001\n",
      "3.21102\n",
      "3.39106\n",
      "2.40472\n",
      "3.38218\n",
      "1.98098\n",
      "2.92347\n",
      "3.59444\n",
      "2.26752\n",
      "3.31341\n",
      "2.55793\n",
      "2.07625\n",
      "2.88587\n",
      "1.97832\n",
      "2.29015\n",
      "2.87726\n",
      "2.42897\n",
      "2.29557\n",
      "2.09245\n",
      "1.69486\n",
      "1.64126\n",
      "2.30906\n",
      "2.13825\n",
      "1.67251\n",
      "1.81112\n",
      "1.98834\n",
      "2.64601\n",
      "1.63192\n",
      "1.90556\n",
      "1.5175\n",
      "2.53958\n",
      "1.67949\n",
      "1.93783\n",
      "2.34648\n",
      "2.1014\n",
      "1.71181\n",
      "1.76806\n",
      "2.21652\n",
      "2.21463\n",
      "2.0038\n",
      "2.1722\n",
      "1.61569\n",
      "1.9372\n",
      "1.75462\n",
      "1.7617\n",
      "1.69369\n",
      "1.82574\n",
      "2.18068\n",
      "0.846798\n",
      "2.08298\n",
      "2.19664\n",
      "2.26733\n",
      "0.888639\n",
      "1.76843\n",
      "1.7277\n",
      "1.29276\n",
      "1.22205\n",
      "1.22357\n",
      "1.78147\n",
      "1.65083\n",
      "1.12965\n",
      "1.16758\n",
      "1.28585\n",
      "1.30761\n",
      "1.44954\n",
      "1.44581\n",
      "1.71503\n",
      "1.91073\n",
      "1.81219\n",
      "2.13708\n",
      "1.23471\n",
      "1.48842\n",
      "1.32811\n",
      "1.49239\n",
      "1.48868\n",
      "0.824442\n",
      "1.73896\n",
      "1.57713\n",
      "1.81098\n",
      "1.4589\n",
      "1.50996\n",
      "1.05357\n",
      "1.84474\n",
      "1.19073\n",
      "0.888535\n",
      "1.68857\n",
      "1.57036\n",
      "1.27995\n",
      "1.48455\n",
      "2.0494\n",
      "1.12923\n",
      "1.09908\n",
      "1.61655\n",
      "1.18989\n",
      "1.51317\n",
      "1.5234\n",
      "1.3205\n",
      "1.55531\n",
      "1.18077\n",
      "1.05682\n",
      "0.931527\n",
      "1.54845\n",
      "0.690796\n",
      "0.817899\n",
      "1.20927\n",
      "1.90146\n",
      "0.858923\n",
      "1.32081\n",
      "1.10818\n",
      "1.31617\n",
      "1.113\n",
      "1.15032\n",
      "1.41355\n",
      "1.86915\n",
      "1.17912\n",
      "0.826922\n",
      "1.32184\n",
      "1.67443\n",
      "1.42356\n",
      "1.27953\n",
      "1.43478\n",
      "1.09279\n",
      "1.35451\n",
      "0.925801\n",
      "1.35009\n",
      "1.12472\n",
      "1.05564\n",
      "1.15174\n",
      "1.24292\n",
      "1.12457\n",
      "1.31511\n",
      "0.902495\n",
      "1.60023\n",
      "0.950277\n",
      "0.830133\n",
      "1.11541\n",
      "0.92549\n",
      "0.548907\n",
      "0.720545\n",
      "0.915095\n",
      "1.33002\n",
      "1.07197\n",
      "1.20185\n",
      "1.07208\n",
      "1.00403\n",
      "1.32404\n",
      "0.836994\n",
      "1.47928\n",
      "0.83921\n",
      "0.553827\n",
      "0.8096\n",
      "1.01836\n",
      "1.78048\n",
      "1.1381\n",
      "1.18604\n",
      "1.38429\n",
      "1.02947\n",
      "1.25626\n",
      "1.31054\n",
      "1.73286\n",
      "1.16584\n",
      "0.814327\n",
      "0.873596\n",
      "0.625942\n",
      "0.921561\n",
      "0.661119\n",
      "0.788349\n",
      "1.48197\n"
     ]
    }
   ],
   "source": [
    "for batch_no in range(total_batches):\n",
    "    mnist_batch = mnist_data.train.next_batch(batch_size)\n",
    "    _, loss_value = session.run([optimiser, loss_operation], feed_dict={\n",
    "        x_input: mnist_batch[0],\n",
    "        y_input: mnist_batch[1]\n",
    "    })\n",
    "    print(loss_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7992\n"
     ]
    }
   ],
   "source": [
    "predictions = tf.argmax(logits, 1)\n",
    "correct_predictions = tf.equal(predictions, tf.argmax(y_input, 1))\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(correct_predictions, tf.float32))\n",
    "test_images, test_labels = mnist_data.test.images, mnist_data.test.labels\n",
    "accuracy_value = session.run(accuracy_operation, feed_dict={\n",
    "    x_input: test_images,\n",
    "    y_input: test_labels\n",
    "})\n",
    "print('Accuracy: ', accuracy_value)\n",
    "session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
